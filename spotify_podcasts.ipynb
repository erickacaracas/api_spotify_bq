{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color=blue size=4> \n",
    "Case 2 - Integração com API Spotify\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação de bibliotecas\n",
    "%pip install requests google-cloud-bigquery google-cloud-secret-manager google-cloud-storage\n",
    "\n",
    "# Importação de bibliotecas\n",
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import secretmanager\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Função para baixar o arquivo de chave JSON do Cloud Storage\n",
    "def service_account_key(bucket_name, file_name, destination_file_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(file_name)\n",
    "\n",
    "    # Baixar o arquivo da chave para o destino\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "    print(f\"Chave de service account baixada para {destination_file_name}\")\n",
    "\n",
    "# Função para configurar o Secret Manager e obter as credenciais do Spotify\n",
    "def get_secret(secret_id):\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "    secret_name = f\"projects/{os.environ['GOOGLE_CLOUD_PROJECT']}/secrets/{secret_id}/versions/latest\" # Garante que a credencial utilizada será a mais atualizada\n",
    "    response = client.access_secret_version(request={\"name\": secret_name})\n",
    "    return json.loads(response.payload.data.decode(\"UTF-8\"))\n",
    "\n",
    "# Obter as credenciais do Spotify armazenadas no Secret Manager\n",
    "spotify_credentials = get_secret(\"spotify-credentials\")\n",
    "\n",
    "# Função para obter o token de acesso do Spotify\n",
    "def acess_token_spotify(client_id, client_secret):\n",
    "    auth_url = \"https://accounts.spotify.com/api/token\"\n",
    "    credentials = f\"{client_id}:{client_secret}\"\n",
    "    encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Basic {encoded_credentials}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(auth_url, headers=headers, data=data)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro ao obter token: {response.text}\")\n",
    "        return None\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "# Função para buscar os primeiros 50 resultados de podcasts relacionados ao termo “data hackers”\n",
    "def busca_podcasts(token, search_term=\"data hackers\"):\n",
    "    search_url = f\"https://api.spotify.com/v1/search?q={search_term}&type=show&market=BR&limit=50\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Erro na busca de podcasts: {response.text}\")\n",
    "        return None\n",
    "\n",
    "    response_data = response.json()\n",
    "    \n",
    "    # Exibir apenas os 2 primeiros resultados para otimizar visualização durante a execução\n",
    "    limited_data = response_data.get('shows', {}).get('items', [])[:2]\n",
    "    print(\"Primeiros 10 podcasts encontrados:\", json.dumps(limited_data, indent=2)) \n",
    "    return response_data.get('shows', {}).get('items', [])\n",
    "    \n",
    "# Função para buscar todos os episódios lançados pelos Data Hackers\n",
    "def busca_episodios(token, show_id):\n",
    "    episodes_url = f\"https://api.spotify.com/v1/shows/{show_id}/episodes\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    \n",
    "    all_episodes = []  # Lista para armazenar todos os episódios\n",
    "    params = {'limit': 50}  # Define um limite de 50 por página\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(episodes_url, headers=headers, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Erro ao buscar episódios: {response.text}\")\n",
    "            return None\n",
    "        \n",
    "        response_data = response.json()\n",
    "        all_episodes.extend(response_data.get('items', []))  # Adiciona os episódios da página atual\n",
    "\n",
    "        # Verifica se há mais páginas\n",
    "        if not response_data.get('next'):  # Se não houver próximo, sai do loop\n",
    "            break\n",
    "        \n",
    "        # Atualiza a URL para a próxima página\n",
    "        episodes_url = response_data.get('next')\n",
    "        \n",
    "    return all_episodes  # Retorna todos os episódios encontrados\n",
    "\n",
    "# Função para salvar os resultados dos podcasts no BigQuery (Tabela 5)\n",
    "def ingestao_bq_podcasts(podcasts, dataset_id, table_id, credentials_path):\n",
    "    # Carregar as credenciais baixadas para service account\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # Nome da tabela atualizada\n",
    "    table_id = \"tb_datahackers_limitada\"\n",
    "    \n",
    "    # Referência para a tabela no BigQuery\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Definir o schema da Tabela 5\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"name\", \"STRING\", description=\"Nome do podcast\"),\n",
    "        bigquery.SchemaField(\"description\", \"STRING\", description=\"Descrição sobre o programa de podcast\"),\n",
    "        bigquery.SchemaField(\"id\", \"STRING\", description=\"Identificador único do programa\"),\n",
    "        bigquery.SchemaField(\"total_episodes\", \"INTEGER\", description=\"Total de episódios lançados até o momento\")\n",
    "    ]\n",
    "\n",
    "    # Criar a tabela se não existir\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "    except Exception:\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "        table.description = \"Tabela 5 - Primeiros 50 resultados referente a podcasts procurando pelo termo 'data hackers'\"\n",
    "        client.create_table(table)\n",
    "\n",
    "    # Preparar os dados para ingestão\n",
    "    rows_to_insert = []\n",
    "    for podcast in podcasts:\n",
    "        if podcast:  # Verifica se o podcast não é None\n",
    "            rows_to_insert.append({\n",
    "                \"name\": podcast.get('name'),\n",
    "                \"description\": podcast.get('description'),\n",
    "                \"id\": podcast.get('id'),\n",
    "                \"total_episodes\": podcast.get('total_episodes', 0),  # Valor padrão se não existir\n",
    "            })\n",
    "\n",
    "    # Inserir os dados na tabela\n",
    "    if rows_to_insert:\n",
    "        errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "        if errors:\n",
    "            print(f\"Erro ao inserir dados no BigQuery: {errors}\")\n",
    "        else:\n",
    "            print(\"Dados inseridos com sucesso na tabela tb_datahackers_limitada.\")\n",
    "\n",
    "# Função para salvar todos os episódios lançados pelo Data Hackers no BigQuery (Tabela 6)\n",
    "def ingestao_bq_episodios(episodios, dataset_id, table_id, credentials_path):\n",
    "    # Carregar as credenciais\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # Nome da tabela atualizada\n",
    "    table_id = \"tb_datahackers_episodios_total\"\n",
    "    \n",
    "    # Referência para a tabela no BigQuery\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Definir o schema da Tabela 6\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"id\", \"STRING\", description=\"Identificação do episódio\"),\n",
    "        bigquery.SchemaField(\"name\", \"STRING\", description=\"Nome do episódio\"),\n",
    "        bigquery.SchemaField(\"description\", \"STRING\", description=\"Descrição do episódio\"),\n",
    "        bigquery.SchemaField(\"release_date\", \"STRING\", description=\"Data de lançamento do episódio\"),\n",
    "        bigquery.SchemaField(\"duration_ms\", \"INTEGER\", description=\"Duração em milissegundos do episódio\"),\n",
    "        bigquery.SchemaField(\"language\", \"STRING\", description=\"Idioma do episódio\"),\n",
    "        bigquery.SchemaField(\"explicit\", \"BOOLEAN\", description=\"Flag se o episódio possui conteúdo explícito\"),\n",
    "        bigquery.SchemaField(\"type\", \"STRING\", description=\"Tipo de faixa de áudio\")\n",
    "    ]\n",
    "\n",
    "    # Criar a tabela se não existir\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "    except Exception:\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "        table.description = \"Tabela 6 - Resultado de todos os episódios lançados pelos Data Hackers\"\n",
    "        client.create_table(table)\n",
    "\n",
    "    # Preparar os dados para ingestão\n",
    "    rows_to_insert = []\n",
    "    for episodio in episodios:\n",
    "        if episodio:  # Verifica se retornou o episódio, evita erro na execução quando não for localizado\n",
    "            rows_to_insert.append({\n",
    "                \"id\": episodio.get('id'),\n",
    "                \"name\": episodio.get('name'),\n",
    "                \"description\": episodio.get('description'),\n",
    "                \"release_date\": episodio.get('release_date'),\n",
    "                \"duration_ms\": episodio.get('duration_ms'),\n",
    "                \"language\": episodio.get('language'),\n",
    "                \"explicit\": episodio.get('explicit'),\n",
    "                \"type\": episodio.get('type'),\n",
    "            })\n",
    "\n",
    "    # Inserir os dados na tabela\n",
    "    if rows_to_insert:\n",
    "        errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "        if errors:\n",
    "            print(f\"Erro ao inserir dados no BigQuery: {errors}\")\n",
    "        else:\n",
    "            print(\"Dados inseridos com sucesso na tabela tb_datahackers_episodios_total.\")\n",
    "\n",
    "# Função para salvar episódios com participação do Grupo Boticário no BigQuery (Tabela 7)\n",
    "def ingestao_bq_episodios_grupo_boticario(episodios, dataset_id, table_id, credentials_path):\n",
    "    # Carregar as credenciais\n",
    "    credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "    client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "    # Nome da tabela atualizada\n",
    "    table_id = \"tb_datahackers_episodios_boticario\"\n",
    "    \n",
    "    # Referência para a tabela no BigQuery\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "    # Definir o schema da Tabela 7\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"id\", \"STRING\", description=\"Identificação do episódio\"),\n",
    "        bigquery.SchemaField(\"name\", \"STRING\", description=\"Nome do episódio\"),\n",
    "        bigquery.SchemaField(\"description\", \"STRING\", description=\"Descrição do episódio\"),\n",
    "        bigquery.SchemaField(\"release_date\", \"STRING\", description=\"Data de lançamento do episódio\"),\n",
    "        bigquery.SchemaField(\"duration_ms\", \"INTEGER\", description=\"Duração em milissegundos do episódio\"),\n",
    "        bigquery.SchemaField(\"language\", \"STRING\", description=\"Idioma do episódio\"),\n",
    "        bigquery.SchemaField(\"explicit\", \"BOOLEAN\", description=\"Flag se o episódio possui conteúdo explícito\"),\n",
    "        bigquery.SchemaField(\"type\", \"STRING\", description=\"Tipo de faixa de áudio\")\n",
    "    ]\n",
    "\n",
    "    # Criar a tabela se não existir\n",
    "    try:\n",
    "        client.get_table(table_ref)\n",
    "    except Exception:\n",
    "        table = bigquery.Table(table_ref, schema=schema)\n",
    "        table.description = \"Tabela 7 - Episódios com participação do Grupo Boticário\"\n",
    "        client.create_table(table)\n",
    "\n",
    "    # Preparar os dados para ingestão\n",
    "    rows_to_insert = []\n",
    "    for episodio in episodios:\n",
    "        if episodio and 'Grupo Boticário' in episodio.get('description', ''):  # Filtra episódios que contém \"Grupo Boticário\" na descrição.\n",
    "            rows_to_insert.append({\n",
    "                \"id\": episodio.get('id'),\n",
    "                \"name\": episodio.get('name'),\n",
    "                \"description\": episodio.get('description'),\n",
    "                \"release_date\": episodio.get('release_date'),\n",
    "                \"duration_ms\": episodio.get('duration_ms'),\n",
    "                \"language\": episodio.get('language'),\n",
    "                \"explicit\": episodio.get('explicit'),\n",
    "                \"type\": episodio.get('type'),\n",
    "            })\n",
    "\n",
    "    # Inserir os dados na tabela\n",
    "    if rows_to_insert:\n",
    "        errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "        if errors:\n",
    "            print(f\"Erro ao inserir dados no BigQuery: {errors}\")\n",
    "        else:\n",
    "            print(\"Dados inseridos com sucesso na tabela tb_datahackers_episodios_boticario.\")\n",
    "\n",
    "\n",
    "# Função principal que agrupa a lógica de uso das funções\n",
    "def main():\n",
    "    # Variáveis e parâmetros\n",
    "    token = acess_token_spotify(spotify_credentials['client_id'], spotify_credentials['client_secret'])\n",
    "    bucket_name = \"spotify-case-podcasts\" #Informar nome do bucket criado no Cloud Storage \n",
    "    file_name = \"chave_sa.json\" # Informar nome do arquivo .json criado com chave da service account\n",
    "    destination_file_name = \"/tmp/chave_sa.json\"\n",
    "    dataset_id = \"spotify_podcasts\" # Informar nome do dataset criado para armazenar tabelas criadas.\n",
    "    \n",
    "    # Baixar a chave da service account\n",
    "    service_account_key(bucket_name, file_name, destination_file_name)\n",
    "\n",
    "    # Buscar os 50 primeiros resultados para buscar por termo Data Hackers e fazer ingestão no BigQuery\n",
    "    podcasts = busca_podcasts(token)\n",
    "    if podcasts:\n",
    "        ingestao_bq_podcasts(podcasts, dataset_id, \"tb_datahackers_limitada\", destination_file_name)\n",
    "\n",
    "    # Buscar todos os episódios lançados pelo Data Hackers e episódios com participação do Grupo Boticário no BigQuery para fazer ingestão no BigQuery\n",
    "    if podcasts:\n",
    "        podcast_id = podcasts[0]['id']\n",
    "        episodios = busca_episodios(token, podcast_id)\n",
    "        if episodios:\n",
    "            ingestao_bq_episodios(episodios, dataset_id, \"tb_datahackers_episodios_total\", destination_file_name)\n",
    "            ingestao_bq_episodios_grupo_boticario(episodios, dataset_id, \"tb_datahackers_episodios_boticario\", destination_file_name)\n",
    "\n",
    "# Execução da função principal\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
